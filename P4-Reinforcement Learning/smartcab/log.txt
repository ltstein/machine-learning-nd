Simulator.run(): Trial 0
Environment.reset(): Trial set up with start = (8, 5), destination = (8, 1), deadline = 20
RoutePlanner.route_to(): destination = (8, 1)
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -5.0
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -5.5
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -5.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -5.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -6.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -7.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -7.5
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -8.0
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 1
Environment.reset(): Trial set up with start = (8, 3), destination = (3, 1), deadline = 35
RoutePlanner.route_to(): destination = (3, 1)
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -6.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -6.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -8.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -8.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -9.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -9.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -10.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -11.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -11.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -12.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -13.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -13.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -13.5
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -14.0
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -14.0
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -14.0
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -14.0
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -14.0
LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -14.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -15.0
LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'forward')
('state', ['green', None, None, 'right', 'right'])
Mistakes: -15.5
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = -0.5
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 2
Environment.reset(): Trial set up with start = (8, 2), destination = (5, 4), deadline = 25
RoutePlanner.route_to(): destination = (5, 4)
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 3
Environment.reset(): Trial set up with start = (2, 3), destination = (6, 4), deadline = 25
RoutePlanner.route_to(): destination = (6, 4)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -6.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'forward')
('state', ['green', 'forward', None, None, 'right'])
Mistakes: -6.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -6.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -6.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: -6.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -7.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -7.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -7.5
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -7.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -7.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -8.5
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -8.5
LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 4
Environment.reset(): Trial set up with start = (8, 6), destination = (5, 3), deadline = 30
RoutePlanner.route_to(): destination = (5, 3)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', 'left', None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -4.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'left'])
Mistakes: -5.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -5.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -5.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: -5.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 5
Environment.reset(): Trial set up with start = (3, 4), destination = (2, 1), deadline = 20
RoutePlanner.route_to(): destination = (2, 1)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -5.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', 'forward', None, None, 'right'])
Mistakes: -6.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['red', 'forward', None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -7.5
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -7.5
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -8.5
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -8.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -8.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -8.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -9.0
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -9.0
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -9.0
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 6
Environment.reset(): Trial set up with start = (2, 6), destination = (1, 3), deadline = 20
RoutePlanner.route_to(): destination = (1, 3)
('action', None)
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', 'forward', None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 7
Environment.reset(): Trial set up with start = (8, 4), destination = (1, 2), deadline = 45
RoutePlanner.route_to(): destination = (1, 2)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.0
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -3.5
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'left'])
Mistakes: -4.0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -4.0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -4.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -4.0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -4.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -4.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -4.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', None, None, 'right', 'forward'])
Mistakes: -6.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, 'right', 'forward'])
Mistakes: -6.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -6.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -6.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -6.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -6.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 8
Environment.reset(): Trial set up with start = (8, 2), destination = (1, 3), deadline = 40
RoutePlanner.route_to(): destination = (1, 3)
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, 'forward', 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, 'left', 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = -0.5
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -5.5
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -6.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -6.0
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -6.0
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'left'])
Mistakes: -7.0
LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['green', None, None, None, 'left'])
Mistakes: -7.0
LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -7.0
LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -7.0
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -7.0
LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -7.0
LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 9
Environment.reset(): Trial set up with start = (5, 1), destination = (7, 4), deadline = 25
RoutePlanner.route_to(): destination = (7, 4)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -2.5
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 10
Environment.reset(): Trial set up with start = (6, 3), destination = (3, 5), deadline = 25
RoutePlanner.route_to(): destination = (3, 5)
('action', None)
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'left')
('state', ['green', None, None, 'right', 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: -4.0
LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 11
Environment.reset(): Trial set up with start = (8, 3), destination = (2, 3), deadline = 30
RoutePlanner.route_to(): destination = (2, 3)
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: -4.5
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 12
Environment.reset(): Trial set up with start = (7, 2), destination = (5, 4), deadline = 20
RoutePlanner.route_to(): destination = (5, 4)
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['red', 'forward', None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', 'forward', None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, 'forward', None, 'left'])
Mistakes: -3.5
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, 'forward', 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -5.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -5.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -5.5
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -6.5
LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 13
Environment.reset(): Trial set up with start = (5, 3), destination = (2, 6), deadline = 30
RoutePlanner.route_to(): destination = (2, 6)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -2.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 14
Environment.reset(): Trial set up with start = (5, 3), destination = (7, 6), deadline = 25
RoutePlanner.route_to(): destination = (7, 6)
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 15
Environment.reset(): Trial set up with start = (2, 6), destination = (7, 1), deadline = 50
RoutePlanner.route_to(): destination = (7, 1)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 50, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 49, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 47, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 46, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -5.5
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'left'])
Mistakes: -6.5
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -6.5
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'left'])
Mistakes: -7.5
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -8.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -8.0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -8.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -8.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -8.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -8.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -9.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -9.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, 'forward', None, 'forward'])
Mistakes: -9.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, 'forward', None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -9.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = 12.0
Simulator.run(): Trial 16
Environment.reset(): Trial set up with start = (2, 1), destination = (6, 6), deadline = 45
RoutePlanner.route_to(): destination = (6, 6)
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['red', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.5
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, 'left', 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = left, reward = -0.5
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -5.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -5.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -5.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -5.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -5.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -5.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -5.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -6.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -6.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -7.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: -7.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 17
Environment.reset(): Trial set up with start = (7, 6), destination = (4, 1), deadline = 40
RoutePlanner.route_to(): destination = (4, 1)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['red', 'left', None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', 'left', None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -4.5
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 18
Environment.reset(): Trial set up with start = (6, 3), destination = (4, 1), deadline = 20
RoutePlanner.route_to(): destination = (4, 1)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', 'right', None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': 'right', 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 19
Environment.reset(): Trial set up with start = (6, 4), destination = (2, 1), deadline = 35
RoutePlanner.route_to(): destination = (2, 1)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['green', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -4.5
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 6, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -4.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 20
Environment.reset(): Trial set up with start = (7, 2), destination = (4, 5), deadline = 30
RoutePlanner.route_to(): destination = (4, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: -0.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 21
Environment.reset(): Trial set up with start = (5, 3), destination = (1, 3), deadline = 20
RoutePlanner.route_to(): destination = (1, 3)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.5
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 0, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 22
Environment.reset(): Trial set up with start = (8, 1), destination = (2, 2), deadline = 35
RoutePlanner.route_to(): destination = (2, 2)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 23
Environment.reset(): Trial set up with start = (6, 5), destination = (1, 5), deadline = 25
RoutePlanner.route_to(): destination = (1, 5)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', 'forward', None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, 'right', 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 4, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 2, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 1, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 24
Environment.reset(): Trial set up with start = (4, 3), destination = (8, 1), deadline = 30
RoutePlanner.route_to(): destination = (8, 1)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, 'left', 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -4.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 25
Environment.reset(): Trial set up with start = (8, 1), destination = (1, 5), deadline = 55
RoutePlanner.route_to(): destination = (1, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 55, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 54, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 53, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 52, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 51, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 50, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 49, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 48, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 47, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 46, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: -0.5
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 26
Environment.reset(): Trial set up with start = (7, 2), destination = (2, 1), deadline = 30
RoutePlanner.route_to(): destination = (2, 1)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 27
Environment.reset(): Trial set up with start = (6, 3), destination = (5, 6), deadline = 20
RoutePlanner.route_to(): destination = (5, 6)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 28
Environment.reset(): Trial set up with start = (7, 3), destination = (1, 3), deadline = 30
RoutePlanner.route_to(): destination = (1, 3)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 29
Environment.reset(): Trial set up with start = (8, 1), destination = (2, 3), deadline = 40
RoutePlanner.route_to(): destination = (2, 3)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -3.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', 'right', None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -4.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -4.0
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -4.0
LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 30
Environment.reset(): Trial set up with start = (6, 5), destination = (3, 2), deadline = 30
RoutePlanner.route_to(): destination = (3, 2)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', 'right', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': 'right', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 31
Environment.reset(): Trial set up with start = (3, 1), destination = (1, 3), deadline = 20
RoutePlanner.route_to(): destination = (1, 3)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -0.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: -0.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 32
Environment.reset(): Trial set up with start = (7, 2), destination = (4, 6), deadline = 35
RoutePlanner.route_to(): destination = (4, 6)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -2.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 33
Environment.reset(): Trial set up with start = (5, 5), destination = (1, 1), deadline = 40
RoutePlanner.route_to(): destination = (1, 1)
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['red', None, None, 'right', 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, 'right', 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -2.0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 34
Environment.reset(): Trial set up with start = (3, 3), destination = (8, 4), deadline = 30
RoutePlanner.route_to(): destination = (8, 4)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 35
Environment.reset(): Trial set up with start = (1, 3), destination = (5, 1), deadline = 30
RoutePlanner.route_to(): destination = (5, 1)
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -2.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 36
Environment.reset(): Trial set up with start = (1, 2), destination = (7, 5), deadline = 45
RoutePlanner.route_to(): destination = (7, 5)
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['red', 'left', None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'right')
('state', ['red', 'left', None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -2.5
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.5
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = -1.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -3.5
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 37
Environment.reset(): Trial set up with start = (4, 3), destination = (2, 1), deadline = 20
RoutePlanner.route_to(): destination = (2, 1)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, 'left', None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 38
Environment.reset(): Trial set up with start = (8, 4), destination = (1, 4), deadline = 35
RoutePlanner.route_to(): destination = (1, 4)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['red', 'forward', None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', 'forward', None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, 'forward', 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -2.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, 'forward', 'left'])
Mistakes: -3.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, 'forward', 'left'])
Mistakes: -3.5
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = -0.5
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 4, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 3, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 2, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 1, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -3.5
LearningAgent.update(): deadline = 0, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
Environment.step(): Primary agent ran out of time! Trial aborted.
Simulator.run(): Trial 39
Environment.reset(): Trial set up with start = (4, 5), destination = (8, 6), deadline = 25
RoutePlanner.route_to(): destination = (8, 6)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 40
Environment.reset(): Trial set up with start = (5, 6), destination = (3, 2), deadline = 30
RoutePlanner.route_to(): destination = (3, 2)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 41
Environment.reset(): Trial set up with start = (4, 3), destination = (2, 5), deadline = 20
RoutePlanner.route_to(): destination = (2, 5)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 42
Environment.reset(): Trial set up with start = (6, 2), destination = (1, 4), deadline = 35
RoutePlanner.route_to(): destination = (1, 4)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, 'right', None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 43
Environment.reset(): Trial set up with start = (4, 3), destination = (1, 5), deadline = 25
RoutePlanner.route_to(): destination = (1, 5)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 44
Environment.reset(): Trial set up with start = (5, 6), destination = (8, 1), deadline = 40
RoutePlanner.route_to(): destination = (8, 1)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, 'left', 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 45
Environment.reset(): Trial set up with start = (8, 5), destination = (6, 2), deadline = 25
RoutePlanner.route_to(): destination = (6, 2)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 46
Environment.reset(): Trial set up with start = (3, 3), destination = (5, 1), deadline = 20
RoutePlanner.route_to(): destination = (5, 1)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 47
Environment.reset(): Trial set up with start = (7, 6), destination = (2, 3), deadline = 40
RoutePlanner.route_to(): destination = (2, 3)
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 48
Environment.reset(): Trial set up with start = (8, 3), destination = (1, 5), deadline = 45
RoutePlanner.route_to(): destination = (1, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 49
Environment.reset(): Trial set up with start = (2, 1), destination = (2, 5), deadline = 20
RoutePlanner.route_to(): destination = (2, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 50
Environment.reset(): Trial set up with start = (7, 6), destination = (7, 1), deadline = 25
RoutePlanner.route_to(): destination = (7, 1)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 51
Environment.reset(): Trial set up with start = (2, 5), destination = (1, 2), deadline = 20
RoutePlanner.route_to(): destination = (1, 2)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['red', None, None, 'left', 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, 'left', 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 52
Environment.reset(): Trial set up with start = (4, 2), destination = (4, 6), deadline = 20
RoutePlanner.route_to(): destination = (4, 6)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 53
Environment.reset(): Trial set up with start = (8, 6), destination = (1, 4), deadline = 45
RoutePlanner.route_to(): destination = (1, 4)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, 'left', 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 54
Environment.reset(): Trial set up with start = (7, 1), destination = (4, 4), deadline = 30
RoutePlanner.route_to(): destination = (4, 4)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 55
Environment.reset(): Trial set up with start = (6, 6), destination = (3, 5), deadline = 20
RoutePlanner.route_to(): destination = (3, 5)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, 'left', 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 56
Environment.reset(): Trial set up with start = (1, 1), destination = (1, 6), deadline = 25
RoutePlanner.route_to(): destination = (1, 6)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, 'right', None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'right'}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 57
Environment.reset(): Trial set up with start = (5, 4), destination = (3, 1), deadline = 25
RoutePlanner.route_to(): destination = (3, 1)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 58
Environment.reset(): Trial set up with start = (8, 2), destination = (2, 2), deadline = 30
RoutePlanner.route_to(): destination = (2, 2)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['red', None, None, 'forward', 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = -1.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 59
Environment.reset(): Trial set up with start = (4, 6), destination = (1, 2), deadline = 35
RoutePlanner.route_to(): destination = (1, 2)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 60
Environment.reset(): Trial set up with start = (3, 1), destination = (4, 5), deadline = 25
RoutePlanner.route_to(): destination = (4, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, 'forward', None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 61
Environment.reset(): Trial set up with start = (1, 6), destination = (7, 3), deadline = 45
RoutePlanner.route_to(): destination = (7, 3)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, 'right', 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 62
Environment.reset(): Trial set up with start = (7, 2), destination = (4, 4), deadline = 25
RoutePlanner.route_to(): destination = (4, 4)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 63
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 5), deadline = 40
RoutePlanner.route_to(): destination = (3, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 64
Environment.reset(): Trial set up with start = (8, 2), destination = (1, 2), deadline = 35
RoutePlanner.route_to(): destination = (1, 2)
('action', 'forward')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 65
Environment.reset(): Trial set up with start = (6, 3), destination = (1, 3), deadline = 25
RoutePlanner.route_to(): destination = (1, 3)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 66
Environment.reset(): Trial set up with start = (8, 1), destination = (3, 3), deadline = 35
RoutePlanner.route_to(): destination = (3, 3)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 67
Environment.reset(): Trial set up with start = (8, 5), destination = (3, 3), deadline = 35
RoutePlanner.route_to(): destination = (3, 3)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, 'right', 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', 'forward', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 68
Environment.reset(): Trial set up with start = (4, 3), destination = (1, 2), deadline = 20
RoutePlanner.route_to(): destination = (1, 2)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 7, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 69
Environment.reset(): Trial set up with start = (6, 3), destination = (7, 6), deadline = 20
RoutePlanner.route_to(): destination = (7, 6)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 70
Environment.reset(): Trial set up with start = (2, 5), destination = (6, 5), deadline = 20
RoutePlanner.route_to(): destination = (6, 5)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 71
Environment.reset(): Trial set up with start = (7, 1), destination = (3, 6), deadline = 45
RoutePlanner.route_to(): destination = (3, 6)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 72
Environment.reset(): Trial set up with start = (6, 5), destination = (5, 1), deadline = 25
RoutePlanner.route_to(): destination = (5, 1)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, 'left', None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, 'left', None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = -0.5
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: -1.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 73
Environment.reset(): Trial set up with start = (2, 4), destination = (5, 2), deadline = 25
RoutePlanner.route_to(): destination = (5, 2)
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, 'right', 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': 'right', 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, 'forward', None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = 12.0
Simulator.run(): Trial 74
Environment.reset(): Trial set up with start = (1, 4), destination = (8, 1), deadline = 50
RoutePlanner.route_to(): destination = (8, 1)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 50, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 49, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 48, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 47, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 46, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 75
Environment.reset(): Trial set up with start = (3, 2), destination = (7, 6), deadline = 40
RoutePlanner.route_to(): destination = (7, 6)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 76
Environment.reset(): Trial set up with start = (2, 2), destination = (8, 6), deadline = 50
RoutePlanner.route_to(): destination = (8, 6)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 50, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 49, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 48, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 47, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 46, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 77
Environment.reset(): Trial set up with start = (8, 5), destination = (1, 5), deadline = 35
RoutePlanner.route_to(): destination = (1, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 78
Environment.reset(): Trial set up with start = (6, 2), destination = (2, 4), deadline = 30
RoutePlanner.route_to(): destination = (2, 4)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'right')
('state', ['red', None, None, 'right', 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': 'right', 'left': None}, action = right, reward = -0.5
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -0.5
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -0.5
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -0.5
LearningAgent.update(): deadline = 11, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 79
Environment.reset(): Trial set up with start = (8, 3), destination = (3, 1), deadline = 35
RoutePlanner.route_to(): destination = (3, 1)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', 'forward', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'forward', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': 'forward', 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 80
Environment.reset(): Trial set up with start = (6, 2), destination = (3, 6), deadline = 35
RoutePlanner.route_to(): destination = (3, 6)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 81
Environment.reset(): Trial set up with start = (1, 3), destination = (8, 2), deadline = 40
RoutePlanner.route_to(): destination = (8, 2)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 82
Environment.reset(): Trial set up with start = (5, 2), destination = (2, 4), deadline = 25
RoutePlanner.route_to(): destination = (2, 4)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 83
Environment.reset(): Trial set up with start = (4, 6), destination = (4, 2), deadline = 20
RoutePlanner.route_to(): destination = (4, 2)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['red', None, 'forward', None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['red', None, None, 'left', 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': 'left', 'left': None}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -2.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -2.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 84
Environment.reset(): Trial set up with start = (7, 5), destination = (3, 3), deadline = 30
RoutePlanner.route_to(): destination = (3, 3)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, 'left', 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': 'left', 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 85
Environment.reset(): Trial set up with start = (6, 4), destination = (1, 2), deadline = 35
RoutePlanner.route_to(): destination = (1, 2)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 86
Environment.reset(): Trial set up with start = (5, 6), destination = (8, 4), deadline = 25
RoutePlanner.route_to(): destination = (8, 4)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 87
Environment.reset(): Trial set up with start = (4, 4), destination = (2, 2), deadline = 20
RoutePlanner.route_to(): destination = (2, 2)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 10, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 8, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 88
Environment.reset(): Trial set up with start = (8, 3), destination = (1, 5), deadline = 45
RoutePlanner.route_to(): destination = (1, 5)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 45, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 44, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, 'left', None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 43, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 42, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 41, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 89
Environment.reset(): Trial set up with start = (8, 1), destination = (5, 4), deadline = 30
RoutePlanner.route_to(): destination = (5, 4)
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', 'forward', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': 'forward', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 90
Environment.reset(): Trial set up with start = (1, 6), destination = (5, 4), deadline = 30
RoutePlanner.route_to(): destination = (5, 4)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, None, 'forward', 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = -1.0
('action', 'forward')
('state', ['green', None, None, 'forward', 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': 'forward', 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 91
Environment.reset(): Trial set up with start = (2, 3), destination = (8, 3), deadline = 30
RoutePlanner.route_to(): destination = (8, 3)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 92
Environment.reset(): Trial set up with start = (7, 5), destination = (3, 1), deadline = 40
RoutePlanner.route_to(): destination = (3, 1)
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 40, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 39, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 37, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 36, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 34, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 32, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 31, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 93
Environment.reset(): Trial set up with start = (1, 3), destination = (5, 2), deadline = 25
RoutePlanner.route_to(): destination = (5, 2)
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['red', None, 'forward', None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = forward, reward = -1.0
('action', 'left')
('state', ['green', None, 'forward', None, 'left'])
Mistakes: -1.0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'forward'}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 13, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 12, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 9, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 12.0
Simulator.run(): Trial 94
Environment.reset(): Trial set up with start = (8, 6), destination = (5, 5), deadline = 20
RoutePlanner.route_to(): destination = (5, 5)
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': 'left', 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', 'left', None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': 'left', 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 12.0
Simulator.run(): Trial 95
Environment.reset(): Trial set up with start = (5, 4), destination = (2, 1), deadline = 30
RoutePlanner.route_to(): destination = (2, 1)
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 96
Environment.reset(): Trial set up with start = (6, 6), destination = (7, 3), deadline = 20
RoutePlanner.route_to(): destination = (7, 3)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 97
Environment.reset(): Trial set up with start = (5, 6), destination = (1, 5), deadline = 25
RoutePlanner.route_to(): destination = (1, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 16, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 15, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 14, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 13, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 12, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 11, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 10, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 9, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 8, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 7, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 6, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 5, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 98
Environment.reset(): Trial set up with start = (5, 2), destination = (2, 5), deadline = 30
RoutePlanner.route_to(): destination = (2, 5)
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 30, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', 'right')
('state', ['green', None, None, None, 'right'])
Mistakes: 0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 28, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 27, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 26, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 25, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 24, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 23, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 22, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 21, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: 0
LearningAgent.update(): deadline = 20, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 19, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'left')
('state', ['green', None, None, None, 'left'])
Mistakes: 0
LearningAgent.update(): deadline = 18, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = left, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: 0
LearningAgent.update(): deadline = 17, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 12.0
Simulator.run(): Trial 99
Environment.reset(): Trial set up with start = (4, 1), destination = (7, 6), deadline = 40
RoutePlanner.route_to(): destination = (7, 6)
('action', 'left')
('state', ['red', None, 'forward', None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 40, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': 'forward'}, action = left, reward = -1.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 39, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 38, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 37, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 36, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 35, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 34, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'right')
('state', ['red', None, None, None, 'right'])
Mistakes: -1.0
LearningAgent.update(): deadline = 33, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = right, reward = 2.0
('action', None)
('state', ['red', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 32, inputs = {'light': 'red', 'oncoming': None, 'right': None, 'left': None}, action = None, reward = 0.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 31, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 30, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, None, None, 'forward'])
Mistakes: -1.0
LearningAgent.update(): deadline = 29, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': None}, action = forward, reward = 2.0
('action', 'forward')
('state', ['green', None, 'left', None, 'forward'])
Environment.act(): Primary agent has reached destination!
Mistakes: -1.0
LearningAgent.update(): deadline = 28, inputs = {'light': 'green', 'oncoming': None, 'right': None, 'left': 'left'}, action = forward, reward = 12.0
